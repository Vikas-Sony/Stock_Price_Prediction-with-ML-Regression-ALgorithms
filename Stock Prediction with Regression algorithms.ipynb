{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction with Scikit learn\n",
    "\n",
    "Stock preditction is one of the field where machine learning seems to be working well and there is a lot of research going on to predict stock prices in a better way so as to increase the profits by making smart investments.\n",
    "\n",
    "We will be using the data recorded by DJI in this exercise and tend to predict the stock prices for future days. So, lets start and get familiar with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988-01-04</th>\n",
       "      <td>1952.589966</td>\n",
       "      <td>2030.010010</td>\n",
       "      <td>1950.760010</td>\n",
       "      <td>2015.250000</td>\n",
       "      <td>2015.250000</td>\n",
       "      <td>20880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-05</th>\n",
       "      <td>2056.370117</td>\n",
       "      <td>2075.270020</td>\n",
       "      <td>2021.390015</td>\n",
       "      <td>2031.500000</td>\n",
       "      <td>2031.500000</td>\n",
       "      <td>27200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-06</th>\n",
       "      <td>2036.469971</td>\n",
       "      <td>2058.189941</td>\n",
       "      <td>2012.770020</td>\n",
       "      <td>2037.800049</td>\n",
       "      <td>2037.800049</td>\n",
       "      <td>18800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-07</th>\n",
       "      <td>2019.890015</td>\n",
       "      <td>2061.510010</td>\n",
       "      <td>2004.640015</td>\n",
       "      <td>2051.889893</td>\n",
       "      <td>2051.889893</td>\n",
       "      <td>21370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-01-08</th>\n",
       "      <td>2046.579956</td>\n",
       "      <td>2058.689941</td>\n",
       "      <td>1898.040039</td>\n",
       "      <td>1911.310059</td>\n",
       "      <td>1911.310059</td>\n",
       "      <td>27440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "1988-01-04  1952.589966  2030.010010  1950.760010  2015.250000  2015.250000   \n",
       "1988-01-05  2056.370117  2075.270020  2021.390015  2031.500000  2031.500000   \n",
       "1988-01-06  2036.469971  2058.189941  2012.770020  2037.800049  2037.800049   \n",
       "1988-01-07  2019.890015  2061.510010  2004.640015  2051.889893  2051.889893   \n",
       "1988-01-08  2046.579956  2058.689941  1898.040039  1911.310059  1911.310059   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "1988-01-04  20880000  \n",
       "1988-01-05  27200000  \n",
       "1988-01-06  18800000  \n",
       "1988-01-07  21370000  \n",
       "1988-01-08  27440000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv('19880101_20161231.csv', index_col='Date')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the meaning of different terms in stock market\n",
    "\n",
    "As we can see our data head in above cell, there are a lot of terms as column names which are not very common and are frequently used and recorded when doing the stock market analysis.\n",
    "\n",
    "So, lets try and find what they mean first and how they can help us in predicting the prices.\n",
    "\n",
    "1. Open :  Prices at the start of day.\n",
    "2. High :  Highest price of the day\n",
    "3. Low  :  Lowest price of the day\n",
    "4. Close:  Prices at end of day\n",
    "6. Volume : Number which is traded\n",
    "\n",
    "\n",
    "This is the data that is given to us but it is really not enough to get good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "\n",
    "So, as it turns out our data doesnt have enough predictors to be used to train a satisfactory model.\n",
    "\n",
    "One general way to think about this type of problem is how we in real life will use the data to gain insights. As we think down this road, we deduced that first thing people look to predict this kind of thing is to look for trends in data like average of last week or last month or maybe last year prices can give us some idea on how prices of next day will come out.\n",
    "\n",
    "So, this gives us the idea that if we can find common mathematical operations like average and standard deviations on our data for different periods of time. So, let us try to do that. Next, we will define a function which will give us the dataframe with all these features given any dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    # 6 original features\n",
    "    df_new['open'] = df['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    df_new['close_1'] = df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_1'] = df['Low'].shift(1)\n",
    "    df_new['volume_1'] = df['Volume'].shift(1)\n",
    "    # 31 generated features\n",
    "    # average price\n",
    "    df_new['avg_price_5'] = df['Close'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_price_30'] = df['Close'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_price_365'] = df['Close'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n",
    "    # average volume\n",
    "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_volume_30'] = df['Volume'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "    # standard deviation of prices\n",
    "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n",
    "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n",
    "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "    # standard deviation of volumes\n",
    "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n",
    "    df_new['std_volume_30'] = df['Volume'].rolling(21).std().shift(1)\n",
    "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n",
    "    # # return\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean().shift(1)\n",
    "    df_new['moving_avg_30'] = df_new['return_1'].rolling(21).mean().shift(1)\n",
    "    df_new['moving_avg_365'] = df_new['return_1'].rolling(252).mean().shift(1)\n",
    "    # the target\n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('19880101_20161231.csv', index_col='Date')\n",
    "data = generate_features(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = '1988-01-01'\n",
    "end_train = '2015-12-31'\n",
    "\n",
    "start_test = '2016-01-01'\n",
    "end_test = '2016-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.ix[start_train:end_train]\n",
    "X_train = data_train.drop('close', axis=1).values\n",
    "y_train = data_train['close'].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.ix[start_test:end_test]\n",
    "X_test = data_test.drop('close', axis=1).values\n",
    "y_test = data_test['close'].values\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a model with Linear Regression\n",
    "\n",
    "Now, we have all our new features and we have split our dataset in train and validation sets using our date index.\n",
    "\n",
    "It is time now to try out different algorithms starting with linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 3e-5, 1e-4],\n",
    "    \"eta0\": [0.01, 0.03, 0.1],\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "lr = SGDRegressor(penalty='l2', n_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "lr_best = grid_search.best_estimator_\n",
    "\n",
    "predictions_lr = lr_best.predict(X_scaled_test)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_lr)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_lr)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "Now, as we have the metrics for our linear regression. Let us try to do a bit better and try using random forst regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [50, 70, 80],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [3, 5]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "rf_best = grid_search.best_estimator_\n",
    "\n",
    "predictions_rf = rf_best.predict(X_test)\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_rf)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_rf)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [100, 300, 500], 'epsilon': [0.00003, 0.0001]},\n",
    "    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [10, 100, 1000], 'epsilon': [0.00003, 0.0001]}\n",
    "]\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=2, scoring='r2')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "svr_best = grid_search.best_estimator_\n",
    "\n",
    "predictions_svr = svr_best.predict(X_scaled_test)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_svr)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_svr)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_svr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 10), (30, 30)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate_init': [0.0001, 0.0003, 0.001, 0.01],\n",
    "    'alpha': [0.00003, 0.0001, 0.0003],\n",
    "    'batch_size': [30, 50]\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn = MLPRegressor(random_state=42, max_iter=2000)\n",
    "grid_search = GridSearchCV(nn, param_grid, cv=2, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "nn_best = grid_search.best_estimator_\n",
    "\n",
    "predictions_nn = nn_best.predict(X_scaled_test)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_nn)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_nn)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_nn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
